---
title: "Predict activity quality from activity monitors"
author: "by Venkat"
date: "21st October 2020"
output:
  html_document:
    keep_md: yes
---

##Synopsis

It is easy to gather vast quantities of personal activity details relatively cheaply using Jawbone Up, Nike FuelBand, and Fitbit. These kinds of devices are part of the quantified self-movement, a community of enthusiasts who frequently test themselves to enhance their wellbeing, to find trends in their actions, or because they are tech geeks. One thing people do on a daily basis is measure how much of a given task they do, but how good they do it is rarely quantified. Your purpose in this project would be to use data from accelerometers of 6 participants on the belt, wrist, shoulder, and dumbell. In 5 different ways, they were challenged to execute barbell lifts correctly and incorrectly. 

The purpose of this experiment is to anticipate the way they did the exercise. In the training package, this is the 'class' component.

## Data description

'Classe', a factor variable with 5 stages, is the result variable. Participants were asked to execute one series of 10 repetitions of the Unilateral Dumbbell Biceps Curl in 5 separate fashions for this data set:

-- specifically as per the specification (Class A)
-Throwing the front elbows (Class B)
-- just raise the dumbbell halfway (Class C)
-- The dumbbell is lowered just halfway (Class D)
-to throw the hips towards the front (Class E)

## Initial configuration

The initial setup consists of some appropriate packages being loaded and some variables being initialised. 

```{r configuration, echo=TRUE, results='hide'}

#Data variables
training.file   <- './data/pml-training.csv'
test.cases.file <- './data/pml-testing.csv'
training.url    <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
test.cases.url  <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'

#Directories
if (!file.exists("data")){
  dir.create("data")
}
if (!file.exists("data/submission")){
  dir.create("data/submission")
}

#R-Packages
IscaretInstalled <- require("caret")
if(!IscaretInstalled){
    install.packages("caret")
    library("caret")
    }

IsrandomForestInstalled <- require("randomForest")
if(!IsrandomForestInstalled){
    install.packages("randomForest")
    library("randomForest")
    }

IsRpartInstalled <- require("rpart")
if(!IsRpartInstalled){
    install.packages("rpart")
    library("rpart")
    }

IsRpartPlotInstalled <- require("rpart.plot")
if(!IsRpartPlotInstalled){
    install.packages("rpart.plot")
    library("rpart.plot")
    }

# Set seed for reproducability
set.seed(9999)
```

## Data processing
The data is downloaded and stored in this chapter. There will be some simple transformations and cleanup, such that 'NA' values are omitted. In the subset, obsolete columns such as "user I d", "raw timestamp part 1", "raw timestamp part 2", "cvtd timestamp", "current window" and "num window" (columns 1 to 7) would be excluded.
To devise instruction and research packages, the 'pml-training.csv' data is used.
The 'pml-test.csv' data is used to predict and answer the 20 questions based on the style of training.

```{r dataprocessing, echo=TRUE, results='hide'}
# Download data
download.file(training.url, training.file)
download.file(test.cases.url,test.cases.file )

# Clean data
training   <-read.csv(training.file, na.strings=c("NA","#DIV/0!", ""))
testing <-read.csv(test.cases.file , na.strings=c("NA", "#DIV/0!", ""))
training<-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]

# Subset data
training   <-training[,-c(1:7)]
testing <-testing[,-c(1:7)]
```

## Cross-validation
In this section cross-validation will be performed by splitting the training data in training (75%) and testing (25%) data.

```{r datasplitting, echo=TRUE, results='hide'}
subSamples <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
subTraining <- training[subSamples, ] 
subTesting <- training[-subSamples, ]
```

## Expected out-of-sample error
Cross-validation will be carried out in this section by separating the training data into training (75 percent) and research data (25 percent).
In the cross-validation results, the predicted out-of-sample error would fit the quantity: 1-accuracy. Accuracy is the percentage in the subTesting data collection of the right classified finding over the overall sample. The estimated precision in the out-of-sample data collection (i.e. the initial test data collection) is the estimated accuracy..

## Exploratory analysis
The variable `classe` contains 5 levels. The plot of the outcome variable shows the frequency of each levels in the subTraining data.

```{r exploranalysis, echo=TRUE}
plot(subTraining$classe, col="orange", main="Levels of the variable classe", xlab="classe levels", ylab="Frequency")
```

The plot above shows that Level A is the most frequent classe. D appears to be the least frequent one.

## Prediction models
In this section a decision tree and random forest will be applied to the data.

### Decision tree
```{r decisiontree, echo=TRUE}
# Fit model
modFitDT <- rpart(classe ~ ., data=subTraining, method="class")

# Perform prediction
predictDT <- predict(modFitDT, subTesting, type = "class")

# Plot result
rpart.plot(modFitDT, main="Classification Tree", extra=102, under=TRUE, faclen=0)
```

Following confusion matrix shows the errors of the prediction algorithm.

```{r decisiontreecm, echo=TRUE}
confusionMatrix(predictDT, subTesting$classe)
```

### Random forest
```{r randomforest, echo=TRUE}
# Fit model
modFitRF <- randomForest(classe ~ ., data=subTraining, method="class")

# Perform prediction
predictRF <- predict(modFitRF, subTesting, type = "class")
```

Following confusion matrix shows the errors of the prediction algorithm.

```{r randomforestcm, echo=TRUE}
confusionMatrix(predictRF, subTesting$classe)
```

## Conclusion

### Result

The uncertainty matrices demonstrate that the algorithm of the Random Forest performs better than the decision trees. For the Random Forest model, the precision was 0.995 (95 % CI: (0.993, 0.997)) relative to 0.739 (95 % CI: (0.727, 0.752)) for the Decision Tree model. The precision was 0.739 (95 % CI: (0.727, 0.752)). A random model of the forest is selected.

### Expected out-of-sample error
It is calculated that the predicted out-of-sample error is 0.005, or 0.5%. For predictions made against the cross-validation range, the predicted out-of-sample error is determined as 1-accuracy. 20 instances are included in our research data collection. We may expect very little, or none, of the test samples to be misclassified with an accuracy above 99 percent on our cross-validation results..

## Submission
In this section the files for the project submission are generated using the random forest algorithm on the testing data.

```{r submission, echo=TRUE}
# Perform prediction
predictSubmission <- predict(modFitRF, testing, type="class")
predictSubmission

# Write files for submission
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./data/submission/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictSubmission)